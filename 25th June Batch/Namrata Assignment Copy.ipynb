{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f87c65",
   "metadata": {},
   "source": [
    "# scaling techniques in machine earning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185d14ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a27b47f",
   "metadata": {},
   "source": [
    "# without scaling our data is not like we could compare and make some conclusions ,this is because they are measured diffrently so they varies  a lot in magnitudes,units and range so for comparing the data we need to bring whole data on the same scale,for doing this we perform feature scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d854a149",
   "metadata": {},
   "source": [
    "## for example :if we want to compare weight and price our model will think that weight is more so it will give more importance or weightage to weight column than price which is not correct so in this scenario we have to take data on the same level so that we can compare it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bbd2b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orange</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Banana</td>\n",
       "      <td>36</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Grape</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Name  Weight  Price\n",
       "0  orange      50      6\n",
       "1   Apple      32      2\n",
       "2  Banana      36      9\n",
       "3   Grape      66      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=[[\"orange\",50,6],[\"Apple\",32,2],[\"Banana\",36,9],[\"Grape\",66,1]]\n",
    "data=pd.DataFrame(df,columns=[\"Name\",\"Weight\",\"Price\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98c99c8",
   "metadata": {},
   "source": [
    "# there are three types of feature scaling techninques:\n",
    "### 1.MinMaxScaler\n",
    "### 2.StandardScaler\n",
    "### 3.RobustScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef811e9d",
   "metadata": {},
   "source": [
    "## 1.MinMaxScaler:it is the scikit-learn function used for normalizing the data and values in a column are shifted in a range of 0 and 1.\n",
    "\n",
    "## 2.StandardScaler:we use z-score for standardizing the data and making it of standard normal distribution of whose mean is zero and standard deviation is 1.StandardScaler is the function of scikit-learn library which we use for standardizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87ee0a",
   "metadata": {},
   "source": [
    "# when to use normalization and when to use standardization:\n",
    "### whenever we have to find out the distance measure between two items i.e.,whenever we have to see that what is the degree of dissimilarity between the two items in these cases standardization is used and also we use it when data has outliers as it does not have any bounding range.It is beneficial to use normalization where dataset follows  gaussian distribution.\n",
    "### unlike standardization normalization should be used where data does not follow Gaussian distribution,and it is used particularly in computer vision and image processing where pixel intensities have to be normalised in order to fit within the RGB colour range between 0 and 255,moreover neural network algorithms require normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d03b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
